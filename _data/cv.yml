- title: Education
  type: time_table
  contents:
    - title: Ph.D. in Applied Mathematics
      institution: Yale University
      # year: 2025 (expected)
      description:
        - Advised by Ronald Coifman and Yuval Kluger.
        
    - title: B.S. in Computer Science and Mathematics
      institution: Yale University
      # year: 2017
      #description:
        #- Description 1.

- title: Experience
  type: time_table
  contents:
    - title: Research Intern
      institution: Google DeepMind
      year: 2025
      description:
        - Designing foundation models for audio generation with applications to sound understanding. Mentors John Hershey.

    - title: Research Intern
      institution: ByteDance / TikTok Seed Foundation Team
      year: 2024
      description:
        - Built multimodal image / language models on the AI Seed-Vision Team, with a focus on diﬀusion-based frameworks. Acquired large-scale datasets (100M+ images / text) and trained diﬀusion models for simultaneous text-to-image, image-to-text, and visual understanding. Results published at CVPR 2025. Mentors Heng Wang, Peng Wang, and Linjie Yang.
        
    - title: Research Intern
      institution: Elucid
      year: 2024
      description:
        - Developed multimodal foundation models to aid in generating and augmenting arterial CT imagery and segmentations for improved fractional flow reserve (FFR) analysis and cardiologist report generation.
    
    - title: Research Intern
      institution: Bosch Center for Artificial Intelligence
      year: 2023
      description:
        - Conducted research on robust training-free approaches to guided diffusion models using optimal control. Published at NeurIPS 2024. Mentor Marcus Pereira.

    - title: Research Intern
      institution: Center for Computational Mathematics, Flatiron Institute
      year: 2020
      description:
        - Explored deep image prior-based techniques for enhancing phase retrieval in low-photon settings at the Center for Computational Mathematics (CCM) at Flatiron Institute

    - title: Software Engineering Intern
      institution: Amazon Lab126
      year: 2016
      description:
        - Modified machine learning module (an n-gram Markov model) in FireOS to reduce memory usage by ~2x with no significant reduction in prediction quality

#- title: Reviewing Responsibilities
#  type: time_table
#  contents:
#    - title: ICML, NeurIPS, ICLR
#      year: 2022
#      description: ICML Outstanding Reviewer, ~top 10%
#    - title: NeurIPS
#      year: 2021
#    - title: TMLR
#      year: Rolling


#- title: Open Source Projects
  #type: time_table
  #contents:
    #- title: <a href="https://github.com/alshedivat/al-folio">al-folio</a>
      #year: 2015-now
      #description: A beautiful, simple, clean, and responsive Jekyll theme for academics.

#- title: Honors and Awards
  #type: time_table
  #contents:
    #- year: 1921
      #items: 
        #- Nobel Prize in Physics 
        #- Matteucci Medal
    #- year: 2029
      #items: 
        #- Max Planck Medal

#- title: Academic Interests
  #type: nested_list
  #contents:
    #- title: Topic 1.
      #items: 
        #- Description 1.
        #- Description 2.
    #- title: Topic 2.
      #items:
        #- Description 1.
        #- Description 2.

#- title: Other Interests
  #type: list
  #contents:
    #- <u>Hobbies:</u> Hobby 1, Hobby 2, etc.
